{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbb7ca0",
   "metadata": {},
   "source": [
    "# Phase 1: Data Processing\n",
    "\n",
    "This notebook shows all the data processing steps and checks the data at each step\n",
    "\n",
    "Steps:\n",
    "1. load the raw data\n",
    "2. clean up resumes  \n",
    "3. clean up jobs\n",
    "4. map occupations together\n",
    "5. split into train/test sets\n",
    "6. create name variants for each resume\n",
    "7. make job-resume pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0c75f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "import all the stuff we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dec6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import difflib\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62ddb1",
   "metadata": {},
   "source": [
    "## 2. Set Up File Paths\n",
    "\n",
    "define where all the data files are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447962b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths configured\n"
     ]
    }
   ],
   "source": [
    "# Raw data\n",
    "RAW_RESUMES = Path(\"../data/raw/resume-dataset.csv\")\n",
    "RAW_JOBS = Path(\"../data/raw/jobs.csv\")\n",
    "\n",
    "# paths to processed data files\n",
    "RESUMES_CLEAN = Path(\"../data/processed/resumes_clean.jsonl\")\n",
    "JOBS_CLEAN = Path(\"../data/processed/jobs_clean.jsonl\")\n",
    "OCCUPATION_MAP = Path(\"../data/processed/occupation_map.json\")\n",
    "SPLIT_IDS = Path(\"../data/processed/split_ids.json\")\n",
    "RESUMES_AUGMENTED = Path(\"../data/processed/resumes_augmented.jsonl\")\n",
    "PAIRS = Path(\"../data/processed/job_resume_pairs_phase1.csv\")\n",
    "\n",
    "print(\"Paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca294c8b",
   "metadata": {},
   "source": [
    "## 3. Load Raw Data\n",
    "\n",
    "load the original datasets before any cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7b27949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW DATA STATS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      " Resumes (resume-dataset.csv):\n",
      "   Total records: 2,484\n",
      "   Columns: ['ID', 'Resume_str', 'Resume_html', 'Category']\n",
      "   Unique categories: 24\n",
      "   File size: 53.7 MB\n",
      "\n",
      " Jobs (jobs.csv):\n",
      "   Total records: 4,412\n",
      "   Columns: ['Unnamed: 0', 'ISCO', 'major_job', 'job', 'position', 'location', 'description']\n",
      "   Unique major_job categories: 16\n",
      "   File size: 5.3 MB\n",
      "\n",
      "Resume Categories:\n",
      "Category\n",
      "ACCOUNTANT                118\n",
      "ADVOCATE                  118\n",
      "AGRICULTURE                63\n",
      "APPAREL                    97\n",
      "ARTS                      103\n",
      "AUTOMOBILE                 36\n",
      "AVIATION                  117\n",
      "BANKING                   115\n",
      "BPO                        22\n",
      "BUSINESS-DEVELOPMENT      120\n",
      "CHEF                      118\n",
      "CONSTRUCTION              112\n",
      "CONSULTANT                115\n",
      "DESIGNER                  107\n",
      "DIGITAL-MEDIA              96\n",
      "ENGINEERING               118\n",
      "FINANCE                   118\n",
      "FITNESS                   117\n",
      "HEALTHCARE                115\n",
      "HR                        110\n",
      "INFORMATION-TECHNOLOGY    120\n",
      "PUBLIC-RELATIONS          111\n",
      "SALES                     116\n",
      "TEACHER                   102\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Job Major Categories:\n",
      "major_job\n",
      "ADMINISTRATIVE AND COMMERCIAL MANAGERS                     321\n",
      "BUSINESS AND ADMINISTRATION ASSOCIATE PROFESSIONALS        253\n",
      "BUSINESS AND ADMINISTRATION PROFESSIONALS                  288\n",
      "CLEANERS AND HELPERS                                       202\n",
      "CUSTOMER SERVICES CLERKS                                   239\n",
      "DRIVERS AND MOBILE PLANT OPERATORS                         211\n",
      "HEALTH ASSOCIATE PROFESSIONALS                              73\n",
      "HEALTH PROFESSIONALS                                       626\n",
      "INFORMATION AND COMMUNICATIONS TECHNICIANS                  94\n",
      "INFORMATION AND COMMUNICATIONS TECHNOLOGY PROFESSIONALS    447\n",
      "MARKET-ORIENTED SKILLED AGRICULTURAL WORKERS               121\n",
      "PROTECTIVE SERVICES WORKERS                                111\n",
      "SALES WORKERS                                              185\n",
      "SCIENCE AND ENGINEERING ASSOCIATE PROFESSIONALS            104\n",
      "SCIENCE AND ENGINEERING PROFESSIONALS                      885\n",
      "TEACHING PROFESSIONALS                                     252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read the raw csv files\n",
    "df_resumes_raw = pd.read_csv(RAW_RESUMES)\n",
    "df_jobs_raw = pd.read_csv(RAW_JOBS)\n",
    "\n",
    "print(\"RAW DATA STATS\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"\\n Resumes (resume-dataset.csv):\")\n",
    "print(f\"   Total records: {len(df_resumes_raw):,}\")\n",
    "print(f\"   Columns: {list(df_resumes_raw.columns)}\")\n",
    "print(f\"   Unique categories: {df_resumes_raw['Category'].nunique()}\")\n",
    "print(f\"   File size: {RAW_RESUMES.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "print(f\"\\n Jobs (jobs.csv):\")\n",
    "print(f\"   Total records: {len(df_jobs_raw):,}\")\n",
    "print(f\"   Columns: {list(df_jobs_raw.columns)}\")\n",
    "print(f\"   Unique major_job categories: {df_jobs_raw['major_job'].nunique()}\")\n",
    "print(f\"   File size: {RAW_JOBS.stat().st_size / (1024*1024):.1f} MB\")\n",
    "\n",
    "print(\"\\nResume Categories:\")\n",
    "print(df_resumes_raw['Category'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n Job Major Categories:\")\n",
    "print(df_jobs_raw['major_job'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e322f3",
   "metadata": {},
   "source": [
    "## 4. Resume Cleaning\n",
    "\n",
    "check the cleaned resume data (HTML removed, short ones filtered out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbaf9890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUME CLEANING RESULTS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Before cleaning: 2,484 resumes\n",
      "After cleaning:  2,483 resumes\n",
      "Dropped:         1 resumes\n",
      "Retention rate:  99.96%\n",
      "\n",
      "Text Length Statistics:\n",
      "   Min:    688 characters\n",
      "   Median: 5,547 characters\n",
      "   Max:    38,412 characters\n",
      "\n",
      "category distribution after cleaning:\n",
      "occupation\n",
      "accountant                118\n",
      "advocate                  118\n",
      "agriculture                63\n",
      "apparel                    97\n",
      "arts                      103\n",
      "automobile                 36\n",
      "aviation                  117\n",
      "banking                   115\n",
      "bpo                        22\n",
      "business_development      119\n",
      "chef                      118\n",
      "construction              112\n",
      "consultant                115\n",
      "designer                  107\n",
      "digital_media              96\n",
      "engineering               118\n",
      "finance                   118\n",
      "fitness                   117\n",
      "healthcare                115\n",
      "hr                        110\n",
      "information_technology    120\n",
      "public_relations          111\n",
      "sales                     116\n",
      "teacher                   102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the cleaned resumes from jsonl file\n",
    "resumes_clean = []\n",
    "with open(RESUMES_CLEAN, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        resumes_clean.append(json.loads(line))\n",
    "\n",
    "df_resumes_clean = pd.DataFrame(resumes_clean)\n",
    "\n",
    "print(\"RESUME CLEANING RESULTS\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"Before cleaning: {len(df_resumes_raw):,} resumes\")\n",
    "print(f\"After cleaning:  {len(df_resumes_clean):,} resumes\")\n",
    "print(f\"Dropped:         {len(df_resumes_raw) - len(df_resumes_clean)} resumes\")\n",
    "print(f\"Retention rate:  {100 * len(df_resumes_clean) / len(df_resumes_raw):.2f}%\")\n",
    "\n",
    "print(\"\\nText Length Statistics:\")\n",
    "text_lengths = df_resumes_clean['text'].str.len()\n",
    "print(f\"   Min:    {text_lengths.min():,} characters\")\n",
    "print(f\"   Median: {text_lengths.median():,.0f} characters\")\n",
    "print(f\"   Max:    {text_lengths.max():,} characters\")\n",
    "\n",
    "print(\"\\ncategory distribution after cleaning:\")\n",
    "print(df_resumes_clean['occupation'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd351f4c",
   "metadata": {},
   "source": [
    "## 5. Job Cleaning\n",
    "\n",
    "check the cleaned job descriptions (parsed and sampled 300 per occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f404f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB CLEANING RESULTS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "before cleaning: 4,412 jobs\n",
      "after cleaning:  3,307 jobs\n",
      "retention rate:  74.95%\n",
      "\n",
      "Description Length Statistics:\n",
      "   Min:    51 characters\n",
      "   Median: 953 characters\n",
      "   Max:    6,536 characters\n",
      "\n",
      "Occupation distribution:\n",
      "occupation\n",
      "administrative_and_commercial_managers                     300\n",
      "business_and_administration_associate_professionals        251\n",
      "business_and_administration_professionals                  286\n",
      "cleaners_and_helpers                                       202\n",
      "customer_services_clerks                                   237\n",
      "drivers_and_mobile_plant_operators                         199\n",
      "health_associate_professionals                              73\n",
      "health_professionals                                       300\n",
      "information_and_communications_technicians                  94\n",
      "information_and_communications_technology_professionals    300\n",
      "market_oriented_skilled_agricultural_workers               119\n",
      "protective_services_workers                                111\n",
      "sales_workers                                              180\n",
      "science_and_engineering_associate_professionals            103\n",
      "science_and_engineering_professionals                      300\n",
      "teaching_professionals                                     252\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the cleaned jobs\n",
    "jobs_clean = []\n",
    "with open(JOBS_CLEAN, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        jobs_clean.append(json.loads(line))\n",
    "\n",
    "df_jobs_clean = pd.DataFrame(jobs_clean)\n",
    "\n",
    "print(\"JOB CLEANING RESULTS\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"before cleaning: {len(df_jobs_raw):,} jobs\")\n",
    "print(f\"after cleaning:  {len(df_jobs_clean):,} jobs\")\n",
    "print(f\"retention rate:  {100 * len(df_jobs_clean) / len(df_jobs_raw):.2f}%\")\n",
    "\n",
    "print(\"\\nDescription Length Statistics:\")\n",
    "desc_lengths = df_jobs_clean['text'].str.len()\n",
    "print(f\"   Min:    {desc_lengths.min():,} characters\")\n",
    "print(f\"   Median: {desc_lengths.median():,.0f} characters\")\n",
    "print(f\"   Max:    {desc_lengths.max():,} characters\")\n",
    "\n",
    "print(\"\\nOccupation distribution:\")\n",
    "print(df_jobs_clean['occupation'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8ec0d",
   "metadata": {},
   "source": [
    "## 6. Occupation Mapping\n",
    "\n",
    "check how resume categories map to job categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bbd8640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCCUPATION MAPPING\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Resume categories mapped: 24\n",
      "Job occupations available: 16\n",
      "\n",
      "first 5 mappings:\n",
      "\n",
      "1. information_technology:\n",
      "   -> information_and_communications_technology_professionals\n",
      "   -> information_and_communications_technicians\n",
      "\n",
      "2. digital_media:\n",
      "   -> information_and_communications_technology_professionals\n",
      "\n",
      "3. engineering:\n",
      "   -> science_and_engineering_professionals\n",
      "   -> science_and_engineering_associate_professionals\n",
      "\n",
      "4. aviation:\n",
      "   -> science_and_engineering_professionals\n",
      "\n",
      "5. automobile:\n",
      "   -> science_and_engineering_professionals\n",
      "   -> drivers_and_mobile_plant_operators\n",
      "\n",
      "coverage: 24/24 resume categories have mappings\n",
      "SUCCESS: all resume categories have job mappings\n"
     ]
    }
   ],
   "source": [
    "# load the occupation mapping file\n",
    "with open(OCCUPATION_MAP, 'r', encoding='utf-8') as f:\n",
    "    occupation_data = json.load(f)\n",
    "\n",
    "# get the actual mapping dictionary\n",
    "occupation_map = occupation_data['mapping']\n",
    "\n",
    "print(\"OCCUPATION MAPPING\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"Resume categories mapped: {len(occupation_map)}\")\n",
    "print(f\"Job occupations available: {df_jobs_clean['occupation'].nunique()}\")\n",
    "\n",
    "print(\"\\nfirst 5 mappings:\")\n",
    "for i, (resume_cat, job_cats) in enumerate(list(occupation_map.items())[:5]):\n",
    "    print(f\"\\n{i+1}. {resume_cat}:\")\n",
    "    for job_cat in job_cats:\n",
    "        print(f\"   -> {job_cat}\")\n",
    "\n",
    "# check if all resume categories are mapped\n",
    "resume_categories = set(df_resumes_clean['occupation'].unique())\n",
    "mapped_categories = set(occupation_map.keys())\n",
    "unmapped = resume_categories - mapped_categories\n",
    "\n",
    "print(f\"\\ncoverage: {len(mapped_categories)}/{len(resume_categories)} resume categories have mappings\")\n",
    "if unmapped:\n",
    "    print(f\"WARNING: Unmapped categories: {unmapped}\")\n",
    "else:\n",
    "    print(\"SUCCESS: all resume categories have job mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c82b3",
   "metadata": {},
   "source": [
    "### Verify Mapping Application\n",
    "\n",
    "Make sure the occupations were actually mapped in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00e76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking resumes_clean data\n",
      "no 'mapped_occupation' column in resumes_clean\n",
      "this is normal - mapping happens in build_pairs.py\n",
      "\n",
      "checking pairs data\n",
      "has 'occupation_match' column: True\n",
      "match rate: 48.4%\n",
      "mismatch rate: 51.6%\n",
      "\n",
      "example matches (first 5):\n",
      "   Resume: business_development           -> Job: administrative_and_commercial_managers\n",
      "   Resume: business_development           -> Job: administrative_and_commercial_managers\n",
      "   Resume: business_development           -> Job: administrative_and_commercial_managers\n",
      "   Resume: business_development           -> Job: administrative_and_commercial_managers\n",
      "   Resume: business_development           -> Job: administrative_and_commercial_managers\n",
      "\n",
      "Example mismatches (first 5):\n",
      "   Resume: healthcare                     -> Job: administrative_and_commercial_managers\n",
      "   Resume: healthcare                     -> Job: administrative_and_commercial_managers\n",
      "   Resume: healthcare                     -> Job: administrative_and_commercial_managers\n",
      "   Resume: healthcare                     -> Job: administrative_and_commercial_managers\n",
      "   Resume: sales                          -> Job: administrative_and_commercial_managers\n",
      "\n",
      "verifying matches are correct (first 10):\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: business_development -> administrative_and_commercial_managers\n",
      "   correct: consultant -> administrative_and_commercial_managers\n",
      "   correct: consultant -> administrative_and_commercial_managers\n"
     ]
    }
   ],
   "source": [
    "# check if resumes have the mapped occupation column\n",
    "print(\"checking resumes_clean data\")\n",
    "if 'mapped_occupation' in df_resumes_clean.columns:\n",
    "    print(f\"found 'mapped_occupation' column\")\n",
    "    print(f\"non-null values: {df_resumes_clean['mapped_occupation'].notna().sum()}/{len(df_resumes_clean)}\")\n",
    "    print(f\"null rate: {df_resumes_clean['mapped_occupation'].isna().mean()*100:.2f}%\")\n",
    "else:\n",
    "    print(\"no 'mapped_occupation' column in resumes_clean\")\n",
    "    print(\"this is normal - mapping happens in build_pairs.py\")\n",
    "\n",
    "print(\"\\nthe occupation mapping will be applied when we build pairs\")\n",
    "print(\"we'll verify it works correctly in the pairs section below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0493c",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split\n",
    "\n",
    "check the split ratios and make sure theres no leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "285cd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN/TEST SPLIT\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "total base resumes: 2,483\n",
      "\n",
      "train: 1,727 (69.6%)\n",
      "val:   361 (14.5%)\n",
      "test:  395 (15.9%)\n",
      "\n",
      "split integrity check:\n",
      "   train intersect test: 0 (should be 0)\n",
      "   Train INTERSECT Val:  0 (should be 0)\n",
      "   Val INTERSECT Test:   0 (should be 0)\n",
      "\n",
      "good, no leakage detected\n"
     ]
    }
   ],
   "source": [
    "# load the split IDs\n",
    "with open(SPLIT_IDS, 'r', encoding='utf-8') as f:\n",
    "    split_ids = json.load(f)\n",
    "\n",
    "train_ids = set(split_ids['train'])\n",
    "val_ids = set(split_ids.get('val', []))\n",
    "test_ids = set(split_ids['test'])\n",
    "\n",
    "total = len(train_ids) + len(val_ids) + len(test_ids)\n",
    "\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"total base resumes: {total:,}\")\n",
    "print(f\"\\ntrain: {len(train_ids):,} ({100 * len(train_ids) / total:.1f}%)\")\n",
    "if val_ids:\n",
    "    print(f\"val:   {len(val_ids):,} ({100 * len(val_ids) / total:.1f}%)\")\n",
    "print(f\"test:  {len(test_ids):,} ({100 * len(test_ids) / total:.1f}%)\")\n",
    "\n",
    "# make sure theres no overlap between splits\n",
    "overlap_train_test = train_ids & test_ids\n",
    "overlap_train_val = train_ids & val_ids\n",
    "overlap_val_test = val_ids & test_ids\n",
    "\n",
    "print(\"\\nsplit integrity check:\")\n",
    "print(f\"   train intersect test: {len(overlap_train_test)} (should be 0)\")\n",
    "if val_ids:\n",
    "    print(f\"   Train INTERSECT Val:  {len(overlap_train_val)} (should be 0)\")\n",
    "    print(f\"   Val INTERSECT Test:   {len(overlap_val_test)} (should be 0)\")\n",
    "\n",
    "if not overlap_train_test and not overlap_train_val and not overlap_val_test:\n",
    "    print(\"\\ngood, no leakage detected\")\n",
    "else:\n",
    "    print(\"\\nwarning: overlap detected between splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74076069",
   "metadata": {},
   "source": [
    "## 8. Name Augmentation\n",
    "\n",
    "check that we created 4 variants for each resume (one for each demographic group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc9b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME AUGMENTATION RESULTS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Base resumes:      2,483\n",
      "Augmented resumes: 9,932\n",
      "Expected variants: 9,932\n",
      "Multiplier:        4.0x\n",
      "\n",
      "Demographic Group Balance:\n",
      "   black_female        : 2,483 (25.0%)\n",
      "   black_male          : 2,483 (25.0%)\n",
      "   white_female        : 2,483 (25.0%)\n",
      "   white_male          : 2,483 (25.0%)\n",
      "\n",
      "SUCCESS: Perfect balance - each group has exactly 25% of variants\n"
     ]
    }
   ],
   "source": [
    "# load augmented resumes\n",
    "resumes_augmented = []\n",
    "with open(RESUMES_AUGMENTED, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        resumes_augmented.append(json.loads(line))\n",
    "\n",
    "df_augmented = pd.DataFrame(resumes_augmented)\n",
    "\n",
    "print(\"NAME AUGMENTATION RESULTS\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"base resumes:      {len(df_resumes_clean):,}\")\n",
    "print(f\"augmented resumes: {len(df_augmented):,}\")\n",
    "print(f\"expected variants: {len(df_resumes_clean) * 4:,}\")\n",
    "print(f\"multiplier:        {len(df_augmented) / len(df_resumes_clean):.1f}x\")\n",
    "\n",
    "print(\"\\ndemographic group counts:\")\n",
    "group_counts = df_augmented['demographic_group'].value_counts().sort_index()\n",
    "for group, cnt in group_counts.items():\n",
    "    pct = 100 * cnt / len(df_augmented)\n",
    "    print(f\"   {group:20s}: {cnt:,} ({pct:.1f}%)\")\n",
    "\n",
    "# check if balanced\n",
    "expected_per_group = len(df_resumes_clean)\n",
    "all_balanced = all(cnt == expected_per_group for cnt in group_counts.values)\n",
    "\n",
    "if all_balanced:\n",
    "    print(\"\\ngood, perfect balance - each group has exactly 25%\")\n",
    "else:\n",
    "    print(\"\\nwarning: imbalance in demographic groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c8afc",
   "metadata": {},
   "source": [
    "## 9. Check that Only Names Changed\n",
    "\n",
    "verify that the 4 variants of each resume are identical except for the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50e37cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTERFACTUAL PROPERTY VERIFICATION\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Base Resume ID: 46258701\n",
      "Number of variants: 4\n",
      "\n",
      "black_female:\n",
      "   Name: Aisha Williams\n",
      "   First 150 chars of text: Aisha Williams\n",
      "\n",
      "HR COORDINATOR Professional Summary Highly efficient Hr Coordinator well established in administrative environments that are fast-pace...\n",
      "\n",
      "black_male:\n",
      "   Name: Jamal Williams\n",
      "   First 150 chars of text: Jamal Williams\n",
      "\n",
      "HR COORDINATOR Professional Summary Highly efficient Hr Coordinator well established in administrative environments that are fast-pace...\n",
      "\n",
      "white_female:\n",
      "   Name: Meredith Williams\n",
      "   First 150 chars of text: Meredith Williams\n",
      "\n",
      "HR COORDINATOR Professional Summary Highly efficient Hr Coordinator well established in administrative environments that are fast-p...\n",
      "\n",
      "white_male:\n",
      "   Name: Matthew Williams\n",
      "   First 150 chars of text: Matthew Williams\n",
      "\n",
      "HR COORDINATOR Professional Summary Highly efficient Hr Coordinator well established in administrative environments that are fast-pa...\n",
      "\n",
      "\n",
      "Base Text Comparison (excluding names):\n",
      "VERIFIED: All 4 variants have IDENTICAL base text\n",
      "Only the prepended name differs across demographic groups.\n"
     ]
    }
   ],
   "source": [
    "# pick a random resume to check\n",
    "sample_base_id = df_augmented['base_resume_id'].iloc[100]\n",
    "variants = df_augmented[df_augmented['base_resume_id'] == sample_base_id].sort_values('demographic_group')\n",
    "\n",
    "print(\"COUNTERFACTUAL CHECK\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"base resume ID: {sample_base_id}\")\n",
    "print(f\"number of variants: {len(variants)}\\n\")\n",
    "\n",
    "# get the base text (skip first 2 lines which have the name)\n",
    "texts = []\n",
    "for _, row in variants.iterrows():\n",
    "    lines = row['text'].split('\\n', 2)\n",
    "    if len(lines) >= 3:\n",
    "        base_text = lines[2]\n",
    "    else:\n",
    "        base_text = row['text']\n",
    "    texts.append(base_text)\n",
    "    print(f\"{row['demographic_group']}:\")\n",
    "    print(f\"   name: {row['name_first']} {row['name_last']}\")\n",
    "    print(f\"   first 150 chars: {row['text'][:150]}\\n\")\n",
    "\n",
    "# check if all base texts are the same\n",
    "all_identical = all(text == texts[0] for text in texts)\n",
    "\n",
    "print(\"\\nbase text comparison:\")\n",
    "if all_identical:\n",
    "    print(\"verified: all 4 variants have identical base text\")\n",
    "    print(\"only the name at the top is different\")\n",
    "else:\n",
    "    print(\"warning: base texts are not identical\")\n",
    "    print(\"\\nshowing differences:\")\n",
    "    for i in range(1, len(texts)):\n",
    "        if texts[i] != texts[0]:\n",
    "            diff = difflib.unified_diff(\n",
    "                texts[0][:500].splitlines(keepends=True),\n",
    "                texts[i][:500].splitlines(keepends=True),\n",
    "                lineterm=''\n",
    "            )\n",
    "            print(f\"\\ndifference between variant 0 and {i}:\")\n",
    "            print(''.join(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bab9f",
   "metadata": {},
   "source": [
    "## 10. Job-Resume Pairs\n",
    "\n",
    "Create (job, resume) pairs for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc71f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAIR GENERATION RESULTS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "total pairs: 9,920\n",
      "unique jobs: 320\n",
      "unique resume variants: 5,968\n",
      "unique base resumes: 1,492\n",
      "\n",
      "pair stats:\n",
      "   avg candidates per job: 31.0\n",
      "   avg jobs per base resume: 6.6\n"
     ]
    }
   ],
   "source": [
    "# load the pairs\n",
    "df_pairs = pd.read_csv(PAIRS)\n",
    "\n",
    "print(\"PAIR GENERATION RESULTS\")\n",
    "print(\"~\" * 50)\n",
    "print(f\"total pairs: {len(df_pairs):,}\")\n",
    "print(f\"unique jobs: {df_pairs['job_id'].nunique():,}\")\n",
    "print(f\"unique resume variants: {df_pairs['resume_variant_id'].nunique():,}\")\n",
    "print(f\"unique base resumes: {df_pairs['base_resume_id'].nunique():,}\")\n",
    "\n",
    "print(\"\\npair stats:\")\n",
    "print(f\"   avg candidates per job: {len(df_pairs) / df_pairs['job_id'].nunique():.1f}\")\n",
    "print(f\"   avg jobs per base resume: {len(df_pairs) / df_pairs['base_resume_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072fdf9",
   "metadata": {},
   "source": [
    "### Verify Occupation Matching in Pairs\n",
    "\n",
    "check that the occupation matching worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61946e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OCCUPATION MATCHING VERIFICATION\")\n",
    "print(\"~\" * 50)\n",
    "\n",
    "# check if the pairs have occupation_match column\n",
    "print(f\"has 'occupation_match' column: {'occupation_match' in df_pairs.columns}\")\n",
    "\n",
    "if 'occupation_match' in df_pairs.columns:\n",
    "    match_rate = df_pairs['occupation_match'].mean()\n",
    "    print(f\"match rate: {match_rate*100:.1f}%\")\n",
    "    print(f\"mismatch rate: {(1-match_rate)*100:.1f}%\")\n",
    "    \n",
    "    # show some example pairings\n",
    "    print(\"\\nexample matches (first 5):\")\n",
    "    sample_matches = df_pairs[df_pairs['occupation_match'] == True].head(5)\n",
    "    for idx, row in sample_matches.iterrows():\n",
    "        print(f\"   Resume: {row['resume_occupation']:30s} -> Job: {row['job_occupation']}\")\n",
    "        \n",
    "    print(\"\\nexample mismatches (first 5):\")\n",
    "    sample_mismatches = df_pairs[df_pairs['occupation_match'] == False].head(5)\n",
    "    for idx, row in sample_mismatches.iterrows():\n",
    "        print(f\"   Resume: {row['resume_occupation']:30s} -> Job: {row['job_occupation']}\")\n",
    "        \n",
    "    # verify matches are correct using our mapping\n",
    "    print(\"\\nverifying matches are correct (first 10):\")\n",
    "    errors = 0\n",
    "    for idx, row in df_pairs[df_pairs['occupation_match'] == True].head(10).iterrows():\n",
    "        resume_occ = row['resume_occupation']\n",
    "        job_occ = row['job_occupation']\n",
    "        expected_jobs = occupation_map.get(resume_occ, [])\n",
    "        is_correct = job_occ in expected_jobs\n",
    "        status = \"✓\" if is_correct else \"✗\"\n",
    "        if not is_correct:\n",
    "            errors += 1\n",
    "        print(f\"   {status} {resume_occ} -> {job_occ}\")\n",
    "    \n",
    "    if errors == 0:\n",
    "        print(\"\\ngood, all sampled matches are correct\")\n",
    "    else:\n",
    "        print(f\"\\nwarning: {errors} errors found in sampled matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aca696",
   "metadata": {},
   "source": [
    "## 11. Check Pair Balance\n",
    "\n",
    "make sure the pairs are balanced across demographics and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb50b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAIR BALANCE ANALYSIS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "1. Occupation Match Balance:\n",
      "   Mismatch    : 5,120 (51.6%)\n",
      "   Match       : 4,800 (48.4%)\n",
      "\n",
      "2. Demographic Group Balance:\n",
      "   black_female        : 2,480 (25.0%)\n",
      "   black_male          : 2,480 (25.0%)\n",
      "   white_female        : 2,480 (25.0%)\n",
      "   white_male          : 2,480 (25.0%)\n",
      "   good, balanced within 1%\n",
      "\n",
      "3. Train/Test Split Balance:\n",
      "   Test  : 1,656 (16.7%)\n",
      "   Train : 6,772 (68.3%)\n",
      "   Val   : 1,492 (15.0%)\n",
      "\n",
      "4. Counterfactual Quartet Completeness:\n",
      "   Total (job, base_resume) pairs: 2,480\n",
      "   Complete quartets (4 variants): 2,480\n",
      "   Incomplete quartets: 0\n",
      "   good, all quartets are complete\n"
     ]
    }
   ],
   "source": [
    "print(\"PAIR BALANCE ANALYSIS\")\n",
    "print(\"~\" * 50)\n",
    "\n",
    "# 1. Match/Mismatch ratio\n",
    "print(\"\\n1. Occupation Match Balance:\")\n",
    "match_counts = df_pairs['occupation_match'].value_counts()\n",
    "for is_match, cnt in match_counts.items():\n",
    "    label = \"Match\" if is_match else \"Mismatch\"\n",
    "    pct = 100 * cnt / len(df_pairs)\n",
    "    print(f\"   {label:12s}: {cnt:,} ({pct:.1f}%)\")\n",
    "\n",
    "# 2. Demographic balance\n",
    "print(\"\\n2. Demographic Group Balance:\")\n",
    "demo_counts = df_pairs['demographic_group'].value_counts().sort_index()\n",
    "for group, cnt in demo_counts.items():\n",
    "    pct = 100 * cnt / len(df_pairs)\n",
    "    print(f\"   {group:20s}: {cnt:,} ({pct:.1f}%)\")\n",
    "\n",
    "# see if balanced within 1%\n",
    "demo_pcts = [100 * cnt / len(df_pairs) for cnt in demo_counts.values]\n",
    "demo_balanced = max(demo_pcts) - min(demo_pcts) < 1.0\n",
    "\n",
    "if demo_balanced:\n",
    "    print(\"   good, balanced within 1%\")\n",
    "else:\n",
    "    print(f\"   warning: imbalance detected ({max(demo_pcts) - min(demo_pcts):.2f}% range)\")\n",
    "\n",
    "# 3. Split balance\n",
    "print(\"\\n3. Train/Test Split Balance:\")\n",
    "split_counts = df_pairs['split'].value_counts().sort_index()\n",
    "for split, cnt in split_counts.items():\n",
    "    pct = 100 * cnt / len(df_pairs)\n",
    "    print(f\"   {split.capitalize():6s}: {cnt:,} ({pct:.1f}%)\")\n",
    "\n",
    "# 4. Quartet completeness\n",
    "print(\"\\n4. Counterfactual Quartet Completeness:\")\n",
    "quartets = df_pairs.groupby(['job_id', 'base_resume_id']).size()\n",
    "incomplete_quartets = quartets[quartets != 4]\n",
    "\n",
    "print(f\"   Total (job, base_resume) pairs: {len(quartets):,}\")\n",
    "print(f\"   Complete quartets (4 variants): {len(quartets[quartets == 4]):,}\")\n",
    "print(f\"   Incomplete quartets: {len(incomplete_quartets):,}\")\n",
    "\n",
    "if len(incomplete_quartets) == 0:\n",
    "    print(\"   good, all quartets are complete\")\n",
    "else:\n",
    "    print(f\"   warning: {len(incomplete_quartets)} incomplete quartets found\")\n",
    "    print(\"\\n   incomplete quartet sizes:\")\n",
    "    print(incomplete_quartets.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be2534",
   "metadata": {},
   "source": [
    "## 12. Summary Table\n",
    "\n",
    "overview of all the processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fdf15e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1 PIPELINE SUMMARY\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "                  step count                            details\n",
      "        1. raw resumes 2,484                      24 categories\n",
      "           2. raw jobs 4,412                16 major categories\n",
      "    3. cleaned resumes 2,483                   100.0% retention\n",
      "       4. cleaned jobs 3,307 300 per occupation, 16 occupations\n",
      "5. occupation mappings    24                      100% coverage\n",
      "        6. train split 1,727              69.6% of base resumes\n",
      "          7. val split   361              14.5% of base resumes\n",
      "         8. test split   395              15.9% of base resumes\n",
      " 9. augmented variants 9,932                  4 per base resume\n",
      "       10. final pairs 9,920          320 jobs x ~32 candidates\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Phase 1 Complete\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(\"PHASE 1 PIPELINE SUMMARY\")\n",
    "print(\"~\" * 50)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"step\": \"1. raw resumes\", \"count\": f\"{len(df_resumes_raw):,}\", \"details\": f\"{df_resumes_raw['Category'].nunique()} categories\"},\n",
    "    {\"step\": \"2. raw jobs\", \"count\": f\"{len(df_jobs_raw):,}\", \"details\": f\"{df_jobs_raw['major_job'].nunique()} major categories\"},\n",
    "    {\"step\": \"3. cleaned resumes\", \"count\": f\"{len(df_resumes_clean):,}\", \"details\": f\"{100 * len(df_resumes_clean) / len(df_resumes_raw):.1f}% retention\"},\n",
    "    {\"step\": \"4. cleaned jobs\", \"count\": f\"{len(df_jobs_clean):,}\", \"details\": f\"300 per occupation, {df_jobs_clean['occupation'].nunique()} occupations\"},\n",
    "    {\"step\": \"5. occupation mappings\", \"count\": f\"{len(occupation_map)}\", \"details\": \"100% coverage\"},\n",
    "    {\"step\": \"6. train split\", \"count\": f\"{len(train_ids):,}\", \"details\": f\"{100 * len(train_ids) / total:.1f}% of base resumes\"},\n",
    "    {\"step\": \"7. val split\", \"count\": f\"{len(val_ids):,}\", \"details\": f\"{100 * len(val_ids) / total:.1f}% of base resumes\"},\n",
    "    {\"step\": \"8. test split\", \"count\": f\"{len(test_ids):,}\", \"details\": f\"{100 * len(test_ids) / total:.1f}% of base resumes\"},\n",
    "    {\"step\": \"9. augmented variants\", \"count\": f\"{len(df_augmented):,}\", \"details\": \"4 per base resume\"},\n",
    "    {\"step\": \"10. final pairs\", \"count\": f\"{len(df_pairs):,}\", \"details\": f\"{df_pairs['job_id'].nunique()} jobs x ~32 candidates\"},\n",
    "])\n",
    "\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"~\" * 50)\n",
    "print(\"Phase 1 Complete\")\n",
    "print(\"~\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
